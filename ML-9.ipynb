{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "829e1324",
   "metadata": {},
   "outputs": [],
   "source": [
    "nw1=\"In this 20-article special, the TOI+ team covers fascinating tales about the 1971 India-Pakistan War that led to the breakup of Pakistan and the formation of Bangladesh. Build a nuanced understanding of what led to the rift between West and East Pakistan, how India used all the resources and power at its disposal to win a decisive war, and what has been the impact on the people of Bangladesh today. Charges have been framed against 10 accused in the Delhi riots case.Cold wave has been predicted for next three days in Haryana and Punjab. Also, snowfall is likely in some cities of Himachal Pradesh. AstraZeneca (AZN.L) said on Thursday a lab-study of its Covid-19 antibody cocktail, Evusheld, found that the treatment retained neutralising activity against the Omicron coronavirus variant, showing promise for wider use of the therapy. (Reuters)\"\n",
    "nw2=\"Delhi Health Minister Satyendar Jain on Friday said 10 new cases of the new Covid variant Omicron have been detected in the national capital, taking the tally to 20. Ten of these patients have been discharged, he said. The minister said 10 out of the 40 samples sent for genome sequencing tested positive for the new variant. (PTI) Twenty-seven people were feared dead after a blaze at a building in a commercial district of the Japanese city of Osaka on Friday, the local fire department said. TV footage showed dozens of firefighters working inside and outside the eight-storey building after the blaze was extinguished. (Inputs: AFP) Four more persons test positive for Omicron in Hyderabad, taking the total number of the variant cases to 7 in Telangana. Kerala reports 3,404 new cases, 36 deaths, and 4,145 recoveries today in 24 hours.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "575cceb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nw1lst=nw1.split()\n",
    "nw2lst=nw2.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ab8e248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['In', 'this', '20-article', 'special,', 'the', 'TOI+', 'team', 'covers', 'fascinating', 'tales', 'about', 'the', '1971', 'India-Pakistan', 'War', 'that', 'led', 'to', 'the', 'breakup', 'of', 'Pakistan', 'and', 'the', 'formation', 'of', 'Bangladesh.', 'Build', 'a', 'nuanced', 'understanding', 'of', 'what', 'led', 'to', 'the', 'rift', 'between', 'West', 'and', 'East', 'Pakistan,', 'how', 'India', 'used', 'all', 'the', 'resources', 'and', 'power', 'at', 'its', 'disposal', 'to', 'win', 'a', 'decisive', 'war,', 'and', 'what', 'has', 'been', 'the', 'impact', 'on', 'the', 'people', 'of', 'Bangladesh', 'today.', 'Charges', 'have', 'been', 'framed', 'against', '10', 'accused', 'in', 'the', 'Delhi', 'riots', 'case.Cold', 'wave', 'has', 'been', 'predicted', 'for', 'next', 'three', 'days', 'in', 'Haryana', 'and', 'Punjab.', 'Also,', 'snowfall', 'is', 'likely', 'in', 'some', 'cities', 'of', 'Himachal', 'Pradesh.', 'AstraZeneca', '(AZN.L)', 'said', 'on', 'Thursday', 'a', 'lab-study', 'of', 'its', 'Covid-19', 'antibody', 'cocktail,', 'Evusheld,', 'found', 'that', 'the', 'treatment', 'retained', 'neutralising', 'activity', 'against', 'the', 'Omicron', 'coronavirus', 'variant,', 'showing', 'promise', 'for', 'wider', 'use', 'of', 'the', 'therapy.', '(Reuters)'] \n",
      "\n",
      "\n",
      "\n",
      " ['Delhi', 'Health', 'Minister', 'Satyendar', 'Jain', 'on', 'Friday', 'said', '10', 'new', 'cases', 'of', 'the', 'new', 'Covid', 'variant', 'Omicron', 'have', 'been', 'detected', 'in', 'the', 'national', 'capital,', 'taking', 'the', 'tally', 'to', '20.', 'Ten', 'of', 'these', 'patients', 'have', 'been', 'discharged,', 'he', 'said.', 'The', 'minister', 'said', '10', 'out', 'of', 'the', '40', 'samples', 'sent', 'for', 'genome', 'sequencing', 'tested', 'positive', 'for', 'the', 'new', 'variant.', '(PTI)', 'Twenty-seven', 'people', 'were', 'feared', 'dead', 'after', 'a', 'blaze', 'at', 'a', 'building', 'in', 'a', 'commercial', 'district', 'of', 'the', 'Japanese', 'city', 'of', 'Osaka', 'on', 'Friday,', 'the', 'local', 'fire', 'department', 'said.', 'TV', 'footage', 'showed', 'dozens', 'of', 'firefighters', 'working', 'inside', 'and', 'outside', 'the', 'eight-storey', 'building', 'after', 'the', 'blaze', 'was', 'extinguished.', '(Inputs:', 'AFP)', 'Four', 'more', 'persons', 'test', 'positive', 'for', 'Omicron', 'in', 'Hyderabad,', 'taking', 'the', 'total', 'number', 'of', 'the', 'variant', 'cases', 'to', '7', 'in', 'Telangana.', 'Kerala', 'reports', '3,404', 'new', 'cases,', '36', 'deaths,', 'and', '4,145', 'recoveries', 'today', 'in', '24', 'hours.']\n"
     ]
    }
   ],
   "source": [
    "print(nw1lst,\"\\n\\n\\n\\n\",nw2lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb6def17",
   "metadata": {},
   "outputs": [],
   "source": [
    "commonlst=[]\n",
    "for i in nw1lst:\n",
    "    if i in nw2lst:\n",
    "        commonlst.append(i)        \n",
    "for i in nw2lst:\n",
    "    if i in nw1lst:\n",
    "        commonlst.append(i)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "702beb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "finalcommonlst=list(set(commonlst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9cad3f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'and': 5, '10': 1, 'said': 1, 'the': 12, 'Delhi': 1, 'to': 3, 'people': 1, 'for': 2, 'have': 1, 'of': 7, 'a': 3, 'on': 2, 'been': 3, 'in': 3, 'Omicron': 1, 'at': 1} \n",
      "\n",
      "\n",
      " {'and': 2, '10': 2, 'said': 2, 'the': 11, 'Delhi': 1, 'to': 2, 'people': 1, 'for': 3, 'have': 2, 'of': 7, 'a': 3, 'on': 2, 'been': 2, 'in': 5, 'Omicron': 2, 'at': 1}\n"
     ]
    }
   ],
   "source": [
    "count1={}\n",
    "count2={}\n",
    "for i in finalcommonlst:\n",
    "    count1[i]=nw1lst.count(i)\n",
    "    count2[i]=nw2lst.count(i)\n",
    "    \n",
    "print(count1,\"\\n\\n\\n\",count2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca376f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19c018c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and', '10', 'said', 'the', 'Delhi', 'to', 'people', 'for', 'have', 'of', 'a', 'on', 'been', 'in', 'Omicron', 'at'] \n",
      "\n",
      " [5, 1, 1, 12, 1, 3, 1, 2, 1, 7, 3, 2, 3, 3, 1, 1] \n",
      "\n",
      " [2, 2, 2, 11, 1, 2, 1, 3, 2, 7, 3, 2, 2, 5, 2, 1]\n"
     ]
    }
   ],
   "source": [
    "res1 = list(map(str, (count1.keys())))\n",
    "res2 = list(map(int, (count1.values())))\n",
    "res3 = list(map(int, (count2.values())))\n",
    "print(res1,\"\\n\\n\",res2,\"\\n\\n\",res3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1abc8abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict1={\n",
    "    \"COMMON\":res1,\"Frequency 1\":res2,\"Frequency 2\":res3\n",
    "}\n",
    "data=pd.DataFrame(dict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eec1541d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\asus\\anaconda3\\envs\\my_env\\lib\\site-packages (3.6.5)\n",
      "Requirement already satisfied: joblib in c:\\users\\asus\\anaconda3\\envs\\my_env\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\asus\\anaconda3\\envs\\my_env\\lib\\site-packages (from nltk) (2021.8.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\asus\\anaconda3\\envs\\my_env\\lib\\site-packages (from nltk) (4.62.3)\n",
      "Requirement already satisfied: click in c:\\users\\asus\\anaconda3\\envs\\my_env\\lib\\site-packages (from nltk) (8.0.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\anaconda3\\envs\\my_env\\lib\\site-packages (from click->nltk) (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "27f27427",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'punkt' from 'nltk.corpus' (C:\\Users\\ASUS\\anaconda3\\envs\\my_env\\lib\\site-packages\\nltk\\corpus\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10616/1972159719.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mstop_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstopwords\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'english'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpunkt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;31m# punkt=set(punkt.words('english')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'punkt' from 'nltk.corpus' (C:\\Users\\ASUS\\anaconda3\\envs\\my_env\\lib\\site-packages\\nltk\\corpus\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "# from nltk.corpus import punkt\n",
    "# punkt=set(punkt.words('english')\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "21521dfb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "list1=[]\n",
    "for keys,values in count1.items():\n",
    "    if keys in stop_words:\n",
    "        list1.append(keys)\n",
    "for i in list1:\n",
    "        count1.pop(i) \n",
    "        \n",
    "list2=[]\n",
    "for keys,values in count2.items():\n",
    "    if keys in stop_words:\n",
    "        list2.append(keys)\n",
    "for i in list2:\n",
    "        count2.pop(i)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8adb311f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e09f2ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10', 'said', 'Delhi', 'people', 'Omicron'] \n",
      "\n",
      " [1, 1, 1, 1, 1] \n",
      "\n",
      " [2, 2, 1, 1, 2]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMMON</th>\n",
       "      <th>Frequency 1</th>\n",
       "      <th>Frequency 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>said</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Delhi</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>people</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Omicron</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    COMMON  Frequency 1  Frequency 2\n",
       "0       10            1            2\n",
       "1     said            1            2\n",
       "2    Delhi            1            1\n",
       "3   people            1            1\n",
       "4  Omicron            1            2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b292e712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[^\\\\w\\\\s]', '']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punkt=['[^\\w\\s]','']\n",
    "punkt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31767ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "20e8f706",
   "metadata": {},
   "outputs": [],
   "source": [
    "list1=[]\n",
    "for keys,values in count1.items():\n",
    "    if keys in punkt:\n",
    "        list1.append(keys)\n",
    "for i in list1:\n",
    "        count1.pop(i) \n",
    "        \n",
    "list2=[]\n",
    "for keys,values in count2.items():\n",
    "    if keys in punkt:\n",
    "        list2.append(keys)\n",
    "for i in list2:\n",
    "        count2.pop(i)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04213560",
   "metadata": {},
   "outputs": [],
   "source": [
    "list1=[]\n",
    "for keys,values in count1.items():\n",
    "    if keys in punkt:\n",
    "        list1.append(keys)\n",
    "for i in list1:\n",
    "        count1.pop(i) \n",
    "        \n",
    "list2=[]\n",
    "for keys,values in count2.items():\n",
    "    if keys in punkt:\n",
    "        list2.append(keys)\n",
    "for i in list2:\n",
    "        count2.pop(i)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "35aad6a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10', 'said', 'Delhi', 'people', 'Omicron'] \n",
      "\n",
      " [1, 1, 1, 1, 1] \n",
      "\n",
      " [2, 2, 1, 1, 2]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMMON</th>\n",
       "      <th>Frequency 1</th>\n",
       "      <th>Frequency 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>said</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Delhi</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>people</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Omicron</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    COMMON  Frequency 1  Frequency 2\n",
       "0       10            1            2\n",
       "1     said            1            2\n",
       "2    Delhi            1            1\n",
       "3   people            1            1\n",
       "4  Omicron            1            2"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res1 = list(map(str, (count1.keys())))\n",
    "res2 = list(map(int, (count1.values())))\n",
    "res3 = list(map(int, (count2.values())))\n",
    "print(res1,\"\\n\\n\",res2,\"\\n\\n\",res3)\n",
    "dict2={\n",
    "    \"COMMON\":res1,\"Frequency 1\":res2,\"Frequency 2\":res3\n",
    "}\n",
    "data2=pd.DataFrame(dict2)\n",
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3128c1c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textblob\n",
      "  Downloading textblob-0.17.1-py2.py3-none-any.whl (636 kB)\n",
      "Requirement already satisfied: nltk>=3.1 in c:\\users\\asus\\anaconda3\\envs\\my_env\\lib\\site-packages (from textblob) (3.6.5)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\asus\\anaconda3\\envs\\my_env\\lib\\site-packages (from nltk>=3.1->textblob) (2021.8.3)\n",
      "Requirement already satisfied: click in c:\\users\\asus\\anaconda3\\envs\\my_env\\lib\\site-packages (from nltk>=3.1->textblob) (8.0.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\asus\\anaconda3\\envs\\my_env\\lib\\site-packages (from nltk>=3.1->textblob) (4.62.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\asus\\anaconda3\\envs\\my_env\\lib\\site-packages (from nltk>=3.1->textblob) (1.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\anaconda3\\envs\\my_env\\lib\\site-packages (from click->nltk>=3.1->textblob) (0.4.4)\n",
      "Installing collected packages: textblob\n",
      "Successfully installed textblob-0.17.1\n"
     ]
    }
   ],
   "source": [
    "!pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "da46192e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wordcloud\n",
      "  Using cached wordcloud-1.8.1.tar.gz (220 kB)\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\users\\asus\\anaconda3\\envs\\my_env\\lib\\site-packages (from wordcloud) (1.21.4)\n",
      "Requirement already satisfied: pillow in c:\\users\\asus\\anaconda3\\envs\\my_env\\lib\\site-packages (from wordcloud) (8.4.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\asus\\anaconda3\\envs\\my_env\\lib\\site-packages (from wordcloud) (3.5.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\asus\\anaconda3\\envs\\my_env\\lib\\site-packages (from matplotlib->wordcloud) (1.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\asus\\anaconda3\\envs\\my_env\\lib\\site-packages (from matplotlib->wordcloud) (21.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\asus\\anaconda3\\envs\\my_env\\lib\\site-packages (from matplotlib->wordcloud) (3.0.4)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\asus\\anaconda3\\envs\\my_env\\lib\\site-packages (from matplotlib->wordcloud) (4.28.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\asus\\anaconda3\\envs\\my_env\\lib\\site-packages (from matplotlib->wordcloud) (0.11.0)\n",
      "Requirement already satisfied: setuptools-scm>=4 in c:\\users\\asus\\anaconda3\\envs\\my_env\\lib\\site-packages (from matplotlib->wordcloud) (6.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\asus\\anaconda3\\envs\\my_env\\lib\\site-packages (from matplotlib->wordcloud) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\asus\\anaconda3\\envs\\my_env\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.16.0)\n",
      "Requirement already satisfied: tomli>=1.0.0 in c:\\users\\asus\\anaconda3\\envs\\my_env\\lib\\site-packages (from setuptools-scm>=4->matplotlib->wordcloud) (1.2.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\asus\\anaconda3\\envs\\my_env\\lib\\site-packages (from setuptools-scm>=4->matplotlib->wordcloud) (58.0.4)\n",
      "Building wheels for collected packages: wordcloud\n",
      "  Building wheel for wordcloud (setup.py): started\n",
      "  Building wheel for wordcloud (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for wordcloud\n",
      "Failed to build wordcloud\n",
      "Installing collected packages: wordcloud\n",
      "    Running setup.py install for wordcloud: started\n",
      "    Running setup.py install for wordcloud: finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ERROR: Command errored out with exit status 1:\n",
      "   command: 'C:\\Users\\ASUS\\anaconda3\\envs\\my_env\\python.exe' -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\ASUS\\\\AppData\\\\Local\\\\Temp\\\\pip-install-kqa5_bsz\\\\wordcloud_3a8cdf30f94747768cb7bcfb49161741\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\ASUS\\\\AppData\\\\Local\\\\Temp\\\\pip-install-kqa5_bsz\\\\wordcloud_3a8cdf30f94747768cb7bcfb49161741\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d 'C:\\Users\\ASUS\\AppData\\Local\\Temp\\pip-wheel-6z78fafi'\n",
      "       cwd: C:\\Users\\ASUS\\AppData\\Local\\Temp\\pip-install-kqa5_bsz\\wordcloud_3a8cdf30f94747768cb7bcfb49161741\\\n",
      "  Complete output (20 lines):\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-3.9\n",
      "  creating build\\lib.win-amd64-3.9\\wordcloud\n",
      "  copying wordcloud\\color_from_image.py -> build\\lib.win-amd64-3.9\\wordcloud\n",
      "  copying wordcloud\\tokenization.py -> build\\lib.win-amd64-3.9\\wordcloud\n",
      "  copying wordcloud\\wordcloud.py -> build\\lib.win-amd64-3.9\\wordcloud\n",
      "  copying wordcloud\\wordcloud_cli.py -> build\\lib.win-amd64-3.9\\wordcloud\n",
      "  copying wordcloud\\_version.py -> build\\lib.win-amd64-3.9\\wordcloud\n",
      "  copying wordcloud\\__init__.py -> build\\lib.win-amd64-3.9\\wordcloud\n",
      "  copying wordcloud\\__main__.py -> build\\lib.win-amd64-3.9\\wordcloud\n",
      "  copying wordcloud\\stopwords -> build\\lib.win-amd64-3.9\\wordcloud\n",
      "  copying wordcloud\\DroidSansMono.ttf -> build\\lib.win-amd64-3.9\\wordcloud\n",
      "  UPDATING build\\lib.win-amd64-3.9\\wordcloud/_version.py\n",
      "  set build\\lib.win-amd64-3.9\\wordcloud/_version.py to '1.8.1'\n",
      "  running build_ext\n",
      "  building 'wordcloud.query_integral_image' extension\n",
      "  error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  ----------------------------------------\n",
      "  ERROR: Failed building wheel for wordcloud\n",
      "    ERROR: Command errored out with exit status 1:\n",
      "     command: 'C:\\Users\\ASUS\\anaconda3\\envs\\my_env\\python.exe' -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\ASUS\\\\AppData\\\\Local\\\\Temp\\\\pip-install-kqa5_bsz\\\\wordcloud_3a8cdf30f94747768cb7bcfb49161741\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\ASUS\\\\AppData\\\\Local\\\\Temp\\\\pip-install-kqa5_bsz\\\\wordcloud_3a8cdf30f94747768cb7bcfb49161741\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Users\\ASUS\\AppData\\Local\\Temp\\pip-record-2rh9rwxr\\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\\Users\\ASUS\\anaconda3\\envs\\my_env\\Include\\wordcloud'\n",
      "         cwd: C:\\Users\\ASUS\\AppData\\Local\\Temp\\pip-install-kqa5_bsz\\wordcloud_3a8cdf30f94747768cb7bcfb49161741\\\n",
      "    Complete output (20 lines):\n",
      "    running install\n",
      "    running build\n",
      "    running build_py\n",
      "    creating build\n",
      "    creating build\\lib.win-amd64-3.9\n",
      "    creating build\\lib.win-amd64-3.9\\wordcloud\n",
      "    copying wordcloud\\color_from_image.py -> build\\lib.win-amd64-3.9\\wordcloud\n",
      "    copying wordcloud\\tokenization.py -> build\\lib.win-amd64-3.9\\wordcloud\n",
      "    copying wordcloud\\wordcloud.py -> build\\lib.win-amd64-3.9\\wordcloud\n",
      "    copying wordcloud\\wordcloud_cli.py -> build\\lib.win-amd64-3.9\\wordcloud\n",
      "    copying wordcloud\\_version.py -> build\\lib.win-amd64-3.9\\wordcloud\n",
      "    copying wordcloud\\__init__.py -> build\\lib.win-amd64-3.9\\wordcloud\n",
      "    copying wordcloud\\__main__.py -> build\\lib.win-amd64-3.9\\wordcloud\n",
      "    copying wordcloud\\stopwords -> build\\lib.win-amd64-3.9\\wordcloud\n",
      "    copying wordcloud\\DroidSansMono.ttf -> build\\lib.win-amd64-3.9\\wordcloud\n",
      "    UPDATING build\\lib.win-amd64-3.9\\wordcloud/_version.py\n",
      "    set build\\lib.win-amd64-3.9\\wordcloud/_version.py to '1.8.1'\n",
      "    running build_ext\n",
      "    building 'wordcloud.query_integral_image' extension\n",
      "    error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "    ----------------------------------------\n",
      "ERROR: Command errored out with exit status 1: 'C:\\Users\\ASUS\\anaconda3\\envs\\my_env\\python.exe' -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\ASUS\\\\AppData\\\\Local\\\\Temp\\\\pip-install-kqa5_bsz\\\\wordcloud_3a8cdf30f94747768cb7bcfb49161741\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\ASUS\\\\AppData\\\\Local\\\\Temp\\\\pip-install-kqa5_bsz\\\\wordcloud_3a8cdf30f94747768cb7bcfb49161741\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Users\\ASUS\\AppData\\Local\\Temp\\pip-record-2rh9rwxr\\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\\Users\\ASUS\\anaconda3\\envs\\my_env\\Include\\wordcloud' Check the logs for full command output.\n"
     ]
    }
   ],
   "source": [
    "!pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a2555ea1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wordcloud'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10616/377215154.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtextblob\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTextBlob\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mwordcloud\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mWordCloud\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mSTOPWORDS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'wordcloud'"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "from collections import Counter\n",
    "import heapq\n",
    "from itertools import chain\n",
    "import collections\n",
    "import itertools\n",
    "import time\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "from wordcloud import WordCloud,STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03097cf4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
